{
  "hash": "cd4d2a626a887941e38b9e4633f3f297",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Economics 104 - Swiss Labor Market Dataset\"\nimage: ../swiss_labor.png\nauthor: \"Prisha Narasimhan\"\ndate: \"2025-10-15\"\noutput:\n  pdf_document: default\n  html_document: default\ndescription: |\n  <br>\n  This project analyzed the factors influencing labor force participation in Switzerland using the 1981 Swiss Labor Market Dataset. I conducted descriptive analyses of key variables, fitted LPM, Probit, and Logit models, and selected the Logit model as preferred, using average marginal effects to quantify how income, age, education, family structure, and foreign status affect participation.\n--- \n\n## a. \n\nBriefly discuss the question you are trying to answer with your model.\n\nWe are using the Swiss Labor Market Participation Dataset from the 1981 Swiss Health Survey (SOMIPOPS) found in the Journal of Applied Economietrics Data Archive (Gerfin, 1996). The question we will be looking to answer is: \"What factors influence whether an individual participates in the labor force in Switzerland?\" Our (binary) dependent variable is participation, indicating whether an individual is active in the labor force (yes or no). The model includes six predictors: income (log of non-labor income), age (in decades), education (years of formal education), youngkids (number of children under 7), oldkids (number of children 7 or older), and foreign (whether the individual is a foreginer or Swiss). The model includes 2 categorical variables, participation (the dependent variable) and foreign, and 5 continuous variables (income, age, education, youngkids, and oldkids). The source of the data is: Gerfin, M. (1996). Parametric and Semi-Parametric Estimation of the Binary Response Model of Labour Market Participation, Journal of Applied Econometrics, 11, 321–339, available at http://qed.econ.queensu.ca/jae/1996-v11.3/gerfin/.\n\n## b. \n\nProvide a descriptive analysis of your variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(AER)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: car\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: carData\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lmtest\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: zoo\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'zoo'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: sandwich\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: survival\n```\n\n\n:::\n\n```{.r .cell-code}\ndata(\"SwissLabor\")\nSwissLabor <- SwissLabor\n```\n:::\n\n\nParticipation Percentages\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(SwissLabor$participation)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n no yes \n471 401 \n```\n\n\n:::\n\n```{.r .cell-code}\nprop.table(table(SwissLabor$participation)) * 100\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n      no      yes \n54.01376 45.98624 \n```\n\n\n:::\n:::\n\nThe binary dependent variable participation indicates whether an individual participates in the Swiss laber force in the SwissLabor dataset. From the summary table, we see that about 54.01% of individuals participate in the Swiss labor force. This shows that majority of the sample participate in the labor force. \n\nIncome Summary\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(AER)\nlibrary(pastecs)\ndata(\"SwissLabor\")\nstat.desc(SwissLabor$income)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     nbr.val     nbr.null       nbr.na          min          max        range \n8.720000e+02 0.000000e+00 0.000000e+00 7.186901e+00 1.237565e+01 5.188749e+00 \n         sum       median         mean      SE.mean CI.mean.0.95          var \n9.317815e+03 1.064313e+01 1.068557e+01 1.396863e-02 2.741611e-02 1.701470e-01 \n     std.dev     coef.var \n4.124888e-01 3.860242e-02 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(SwissLabor$income)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  7.187  10.472  10.643  10.686  10.887  12.376 \n```\n\n\n:::\n:::\n\n\nHistogram of Income with Density Plot\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(SwissLabor$income, col = \"lightblue\", breaks = 10, xlab = \"Income (log of non-labor income)\", \n     main = \"Histogram of Income\", prob = TRUE, xlim = c(7, 13))\nlines(density(SwissLabor$income), lwd = 2, col = \"red\")\nlines(density(SwissLabor$income, adjust = .5), lwd = 2, col = \"blue\", \n      type = 'l', lty = 2)\nrug(SwissLabor$income)\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThe histogram of the Income (log of non-labor income) indicates that the distribution of the data is left skewed. Therefore we would be looking to use the median as opposed to the mean to measure the central tendency of the data. There is a large range of values, spanning from 7.187 to 12.376. The density plot illustrates a smooth, continuous estimate of the probability density function (PDF) of the data. The blue dotted line is a more precise depiction of the data estimates. It provides a clearer view of the distribution's shape, allowing you to see peaks and valleys. \n\nBoxplot of Income\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(SwissLabor$income, ylab = \"Income (log of non-labor income)\", \n        main = \"Boxplot of Income\", col = \"lightblue\")\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nFrom the boxplot of Income (log of non-labor income), we're able to solidify a few key insights about the data that we learned through prior tools and figures. We're able to see that the median of the data is between 10 and 11, which agrees with the true median of 10.643. We're also able to see the rather small standard deviation of about 4.12e^-1. Both of the whiskers seem to be of similar size with outliers on either end. However, there is a potential outlier seeming to be at the minimum value, influencing the skew of the distribution. The appropriate values of Q1 and Q3 are also displayed, at 10.472 and 10.887, respectively. In addition, the box plot illustrates the min and max of the data, showing a difference of about 5 between the two. \n\nAge Summary\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pastecs)\nstat.desc(SwissLabor$age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     nbr.val     nbr.null       nbr.na          min          max        range \n8.720000e+02 0.000000e+00 0.000000e+00 2.000000e+00 6.200000e+00 4.200000e+00 \n         sum       median         mean      SE.mean CI.mean.0.95          var \n3.484100e+03 3.900000e+00 3.995528e+00 3.573248e-02 7.013183e-02 1.113378e+00 \n     std.dev     coef.var \n1.055167e+00 2.640871e-01 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(SwissLabor$age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   3.200   3.900   3.996   4.800   6.200 \n```\n\n\n:::\n:::\n\n\nHistogram of Age with Density Plot\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(SwissLabor$age, col = \"coral\", breaks = 10, xlab = \"Age (in decades)\", \n     main = \"Histogram of Age\", prob = TRUE, xlim = c(1,7))\nlines(density(SwissLabor$age), lwd = 2, col = \"red\")\nlines(density(SwissLabor$age, adjust = .5), lwd = 2, col = \"blue\", \n      type = 'l', lty = 2)\nrug(SwissLabor$age)\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThe histogram of Age (in decades), has a somewhat central peak and overall looks to behave more normally. To measure the central tendency of the data, we may use either median or mean as there doesn't seem to be heavy skews or deviations from normality. There is a large range of values, spanning from 2 to 6.2. The density plot illustrates a smooth, continuous estimate of the probability density function (PDF) of the data. The blue dotted line is a more precise depiction of the data estimates. It provides a clearer view of the distribution's shape, allowing you to see smaller peaks and valleys.\n\nBoxplot of Age\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(SwissLabor$age, ylab = \"Age (in decades)\", \n        main = \"Boxplot of Age\", col = \"coral\")\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nFrom the boxplot of Age (in decades), we are able to solidify a few key insights about the data that we learned through prior tools and figures. We are able to see that the median of the data is between 3 and 5, which agrees with the true median of 3.9. We are also able to see that the standard deviation of about 1.055. Additionally, both whiskers seem to be of similar size, which no indication of outliers. The appropriate values of Q1 and Q3 are also displayed, at 3.2 and 4.8, respectively. The box plot also illustrates the min and max of the data, showing that the difference is quite large (in decades) between the two. \n\nEducation Summary\n\n::: {.cell}\n\n```{.r .cell-code}\nstat.desc(SwissLabor$education)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     nbr.val     nbr.null       nbr.na          min          max        range \n 872.0000000    0.0000000    0.0000000    1.0000000   21.0000000   20.0000000 \n         sum       median         mean      SE.mean CI.mean.0.95          var \n8116.0000000    9.0000000    9.3073394    0.1028207    0.2018053    9.2188669 \n     std.dev     coef.var \n   3.0362587    0.3262220 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(SwissLabor$education)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   9.307  12.000  21.000 \n```\n\n\n:::\n:::\n\n\nHistogram of Education with Density Plot\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(SwissLabor$education, col = \"mediumaquamarine\", breaks = 10, \n     xlab = \"Education (years of formal education)\", \n     main = \"Histogram of Education\", \n     prob = TRUE, xlim = c(0, 25))\nlines(density(SwissLabor$education), lwd = 2, col = \"red\")\nlines(density(SwissLabor$education, adjust = .5), lwd = 2, col = \"blue\", \n      type = 'l', lty = 2)\nrug(SwissLabor$education)\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nThe histogram of Education (years of formal schooling), indicates that the distribution is slightly right-skewed. So, we would be looking to use the median as opposed to the mean to measure the central tendency of the data. There is a large range of values, spanning from 1 to 21. The density plot illustrates a smooth, continuous estimate of the probability density function (PDF) of the data. The blue dotted line is a more precise depiction of the data estimates. It provides a clearer view of the distribution's shape, allowing you to see smaller peaks and valleys.\n\nBoxplot of Education\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(SwissLabor$education, ylab = \"Education (years of schooling)\", \n        main = \"Boxplot of Education\", col = \"mediumaquamarine\")\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nFrom the boxplot of Education (years of schooling), we are able to solidify a few key insights about the data that we learned about through prior tools and figures. We're able to see that the median of the data is between 8 and 12, which agrees with the true median of 9. We are also able to see the standard deviation of about 3.03. Additionally, both of the whiskers looks to be of similar size, with a few outliers above the median, suggesting the slight right-skew of the distribution. The appropriate values of Q1 and Q3 are also displayed, at 8 and 12. In addition, the box plot illustrates the min and max of the data, showing that the difference rather large between the two. There are a few outliers shown in the box plot on either side of the median (though moreso above the median), matching our previous findings as well. \n\nYoung kids Summary\n\n::: {.cell}\n\n```{.r .cell-code}\nstat.desc(SwissLabor$youngkids)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     nbr.val     nbr.null       nbr.na          min          max        range \n872.00000000 665.00000000   0.00000000   0.00000000   3.00000000   3.00000000 \n         sum       median         mean      SE.mean CI.mean.0.95          var \n272.00000000   0.00000000   0.31192661   0.02075440   0.04073447   0.37560960 \n     std.dev     coef.var \n  0.61286997   1.96478903 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(SwissLabor$youngkids)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.3119  0.0000  3.0000 \n```\n\n\n:::\n:::\n\n\nHistogram of Young kids with Density Plot\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(SwissLabor$youngkids, col = \"indianred\", breaks = 10, \n     xlab = \"Young Kids (number of kids 7 or younger)\", \n     main = \"Histogram of Young Kids\", prob = TRUE, xlim = c(0, 4))\nlines(density(SwissLabor$youngkids), lwd = 2, col = \"red\")\nlines(density(SwissLabor$youngkids, adjust = .5), lwd = 2, col = \"blue\", \n      type = 'l', lty = 2)\nrug(SwissLabor$youngkids)\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThe histogram of the Young Kids (number of kids individuals have that are 7 or younger), indicates that the distribution is extremely right-skewed. Therefore, we would be looking to use the median as opposed to the mean to measure the central tendency of the data. There is a shorter range of values, spanning from 0 to 3. The density plot illustrates a smooth, continuous estimate of the probability density function of the data. The blue dotted line is a more precise depiction of the data estimates. It provides a clearer view of the distribution's shape, allowing you to see smaller peaks and valleys.\n\nBoxplot of Young kids\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(SwissLabor$youngkids, ylab = \"Young Kids\", \n        main = \"Boxplot of Young Kids\", col = \"indianred\")\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nFrom the boxplot of youngkids (the number of kids an individual has that's 7 or younger), we are able to solidify a few key insights about the data that we learned about through prior tools and figures. We are able to see that the median of the data is around 0, which agrees with the true median of 0. We are also able to see the standard deviation of about 0.612. Additionally, the comparatively large outliers above the median suggest the strong right-skew of the distribution. The values of Q1 and Q3 also seem to be around 0. Also, the box plot illustrates the min and max of the data, showing a difference of about 3 between the two. There are a few outliers shown in the box plot exceeding the standard deviation (all above the median), matching our previous findings as well.\n\nOld Kids Summary\n\n::: {.cell}\n\n```{.r .cell-code}\nstat.desc(SwissLabor$oldkids)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     nbr.val     nbr.null       nbr.na          min          max        range \n872.00000000 393.00000000   0.00000000   0.00000000   6.00000000   6.00000000 \n         sum       median         mean      SE.mean CI.mean.0.95          var \n857.00000000   1.00000000   0.98279817   0.03680323   0.07223338   1.18110445 \n     std.dev     coef.var \n  1.08678629   1.10580822 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(SwissLabor$oldkids)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.9828  2.0000  6.0000 \n```\n\n\n:::\n:::\n\n\nHistogram of Old Kids with Density Plot\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(SwissLabor$oldkids, col = \"sandybrown\", breaks = 10, \n     xlab = \"Old Kids (number of kids older than 7)\", \n     main = \"Histogram of Old Kids\", prob = TRUE, xlim = c(0, 25))\nlines(density(SwissLabor$oldkids), lwd = 2, col = \"red\")\nlines(density(SwissLabor$oldkids, adjust = .5), lwd = 2, col = \"blue\", \n      type = 'l', lty = 2)\nrug(SwissLabor$oldkids)\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nThe histogram of the Old Kids (number of kids individuals have that are older than 7), indicates that the distribution is extremely right-skewed. Therefore, we would be looking to use the median as opposed to the mean to measure the central tendency of the data. There is a shorter range of values, spanning from 0 to 6. The density plot illustrates a smooth estimate with many of peaks and valleys of the probability density function of the data. The blue dotted line is a more precise depiction of the data estimatse. It provides a clearer view of the distribution's shape, allowing you to see the many peaks and valleys.\n\nBoxplot of Old Kids\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(SwissLabor$oldkids, ylab = \"Old Kids\", \n        main = \"Boxplot of Old Kids\", col = \"sandybrown\")\n```\n\n::: {.cell-output-display}\n![](04-project_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nFrom the boxplot of Old Kids (the number of kids an individual has that are older than 7), we are able to solidify a few key insights about the data that we learned about through prior tools and figures. We are able to see that the median of the data lies between 0 and 2, which agrees with the true median of 1. We are also able to see that the standard deviation of about 1.08. Additionally, the upper whisker is much longer, suggesting that the data has a right skew with more high values or outliers above the median. The appropriate values of Q1 and Q3 are also displayed, at 0 and 2. In addition, the box plot illustrates the min and max of the data, showing a difference of 6 between the two. There are a few outliers shown in the box plot exceeding the standard deviation (above the median), matching our previous findings as well. \n\nForeign Percentages\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(SwissLabor$foreign)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n no yes \n656 216 \n```\n\n\n:::\n\n```{.r .cell-code}\nprop.table(table(SwissLabor$foreign)) * 100\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n      no      yes \n75.22936 24.77064 \n```\n\n\n:::\n:::\n\n\nThe binary varialbe foreign indicates whether an individual is a foreigner (\"yes) or not (\"no\") in the SwissLabor dataset. From the summary table, we see that about 75.23% of individuals are not foreigners, while 24.8% are foreigners. This shows that majority of the sample consists of non-foreigners, while about a quarter of the sample are foreigners. \n\nCorrelation Matrix\n\n::: {.cell}\n\n```{.r .cell-code}\n# excludes catagorical/binary variables participation and foreign\nnumeric_data <- SwissLabor[, c(\"income\", \"age\", \"education\", \n                               \"youngkids\", \"oldkids\")]\ncor_matrix <- cor(numeric_data, use = \"complete.obs\")\ncor_matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               income         age   education   youngkids     oldkids\nincome     1.00000000  0.00618126  0.32734578 -0.01733803  0.13910359\nage        0.00618126  1.00000000 -0.14929401 -0.51909274 -0.11620515\neducation  0.32734578 -0.14929401  1.00000000  0.09834970 -0.03632097\nyoungkids -0.01733803 -0.51909274  0.09834970  1.00000000 -0.23842829\noldkids    0.13910359 -0.11620515 -0.03632097 -0.23842829  1.00000000\n```\n\n\n:::\n:::\n\n\nThe correlation matrix displays the pairwise relationships betweeen several key continuous predictors in the dataset, including income (log of non-labor income), age (in decades), education (years of schooling), youngkids (number of kids less than 7), and oldkids (number of kids greater than 7). The participation and foreigner variable are not included due to their binary nature. A correlation close to 1 indicates a strong positive relationship, while a correlation close to -1 reflects a strong negative relationship. A correlation near 0 suggests no relationship. There appears to be a moderate positive correlation between education and income, indicating that individuals with higher education tend to have higher non-labor income. In contrast, there appears to be a moderately strong negative correlation between youngkids and age, indicating that younger individuals tend to have more young children. Additionally, there is a somewhat moderate negative correlation between youngkids and oldkids, suggesting that individuals with more children less than 7 tend to not have as many children greater than 7. Other correlations appear to be rather weak or negligible, suggesting low multicollinearity risks amongst predictors. Overall, the matrix helps identify which variables are more closely associated with one another, and informs further analysis and model building.\n\n## c. \n\nFit the three models below, and identify which model is your preferred one.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# LPM \n# convert participation into a binary variable\nSwissLabor$part_num <- ifelse(SwissLabor$participation == \"yes\", 1, 0)\n# fit LPM \nswiss.lpm <- lm(part_num ~ income + age + education + youngkids \n                + oldkids + foreign, data = SwissLabor)\n\n# Probit\nswiss.probit <- glm(participation ~ income + age + education + \n                      youngkids + oldkids + foreign, \n                    data = SwissLabor, family = binomial(link = \"probit\"))\n\n# Logit\nswiss.logit <- glm(participation ~ income + age + education + youngkids + \n                     oldkids + foreign, \n                   data = SwissLabor, family = binomial(link = \"logit\"))\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare the Models - AIC Tests\nAIC(swiss.lpm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1126.542\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(swiss.probit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1066.983\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(swiss.logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1066.798\n```\n\n\n:::\n\n```{.r .cell-code}\n# probit and logit are preferred with very similar results according to AIC tests\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare the Models (probit and logit) - McFadden's R^2 (from scratch)\n\n# probit McFadden\nswiss.null_p <- glm(participation ~ 1, data = SwissLabor, \n                    family = binomial(link = \"probit\"))\nlogLik.full_p <- logLik(swiss.probit)\nlogLik.null_p <- logLik(swiss.null_p)\n\nMcFadden.R2_p <- 1 - (as.numeric(logLik.full_p) / as.numeric(logLik.null_p))\n\nMcFadden.R2_p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1248651\n```\n\n\n:::\n\n```{.r .cell-code}\n# logit McFadden\nswiss.null_l <- glm(participation ~ 1, data = SwissLabor, \n                    family = binomial(link = \"logit\"))\nlogLik.full_l <- logLik(swiss.logit)\nlogLik.null_l <- logLik(swiss.null_l)\n\nMcFadden.R2_l <- 1 - (as.numeric(logLik.full_l) / as.numeric(logLik.null_l))\n\nMcFadden.R2_l\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1250191\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confusion Matrix - Split Data\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: ggplot2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lattice\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'caret'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:survival':\n\n    cluster\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(123)\nSwissLabor$part_num <- ifelse(SwissLabor$participation == \"yes\", 1, 0)\nSwissLabor$foreign_num <- ifelse(SwissLabor$foreign == \"yes\", 1, 0)\n# Split into 70% train, 30% test\ntrain_index <- sample(c(TRUE, FALSE), nrow(SwissLabor), \n                      replace = TRUE, prob = c(0.7, 0.3))\n# Create datasets\ntrain <- SwissLabor[train_index, ]\ntest <- SwissLabor[!train_index, ]\n\n# LPM - Confusion Matrix\nset.seed(123)\nlpm_model <- lm(part_num ~ income + age + education + \n                  youngkids + oldkids + foreign_num, data = train)\npred_lpm <- predict(lpm_model, newdata = test)\nclass_lpm <- ifelse(pred_lpm >= 0.5, 1, 0)\nconfusionMatrix(as.factor(class_lpm), as.factor(test$part_num), positive = \"1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 103  55\n         1  31  67\n                                          \n               Accuracy : 0.6641          \n                 95% CI : (0.6026, 0.7217)\n    No Information Rate : 0.5234          \n    P-Value [Acc > NIR] : 3.568e-06       \n                                          \n                  Kappa : 0.3207          \n                                          \n Mcnemar's Test P-Value : 0.01313         \n                                          \n            Sensitivity : 0.5492          \n            Specificity : 0.7687          \n         Pos Pred Value : 0.6837          \n         Neg Pred Value : 0.6519          \n             Prevalence : 0.4766          \n         Detection Rate : 0.2617          \n   Detection Prevalence : 0.3828          \n      Balanced Accuracy : 0.6589          \n                                          \n       'Positive' Class : 1               \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\n# Probit - Confusion Matrix\nprobit_model <- glm(part_num ~ income + age + education + youngkids + \n                      oldkids + foreign_num, data = train, \n                    family = binomial(link = \"probit\"))\npred_probit <- predict(probit_model, newdata = test, type = \"response\")\nclass_probit <- ifelse(pred_probit >= 0.5, 1, 0)\nconfusionMatrix(as.factor(class_probit), as.factor(test$part_num), positive = \"1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 102  55\n         1  32  67\n                                         \n               Accuracy : 0.6602         \n                 95% CI : (0.5986, 0.718)\n    No Information Rate : 0.5234         \n    P-Value [Acc > NIR] : 6.478e-06      \n                                         \n                  Kappa : 0.313          \n                                         \n Mcnemar's Test P-Value : 0.01834        \n                                         \n            Sensitivity : 0.5492         \n            Specificity : 0.7612         \n         Pos Pred Value : 0.6768         \n         Neg Pred Value : 0.6497         \n             Prevalence : 0.4766         \n         Detection Rate : 0.2617         \n   Detection Prevalence : 0.3867         \n      Balanced Accuracy : 0.6552         \n                                         \n       'Positive' Class : 1              \n                                         \n```\n\n\n:::\n\n```{.r .cell-code}\n# Logit - Confusion Matrix\nlogit_model <- glm(part_num ~ income + age + education + youngkids + \n                     oldkids + foreign_num, data = train, \n                   family = binomial(link = \"logit\"))\npred_logit <- predict(logit_model, newdata = test, type = \"response\")\nclass_logit <- ifelse(pred_logit >= 0.5, 1, 0)\nconfusionMatrix(as.factor(class_logit), as.factor(test$part_num), positive = \"1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 104  55\n         1  30  67\n                                          \n               Accuracy : 0.668           \n                 95% CI : (0.6066, 0.7254)\n    No Information Rate : 0.5234          \n    P-Value [Acc > NIR] : 1.932e-06       \n                                          \n                  Kappa : 0.3283          \n                                          \n Mcnemar's Test P-Value : 0.009237        \n                                          \n            Sensitivity : 0.5492          \n            Specificity : 0.7761          \n         Pos Pred Value : 0.6907          \n         Neg Pred Value : 0.6541          \n             Prevalence : 0.4766          \n         Detection Rate : 0.2617          \n   Detection Prevalence : 0.3789          \n      Balanced Accuracy : 0.6626          \n                                          \n       'Positive' Class : 1               \n                                          \n```\n\n\n:::\n:::\n\n\nBased on the model selection criteria, the logit model is preferred. Both the probit and logit models yield similarly low AIC values, indicating comparable model fit, with the logit model showing a very slightly lower AIC. Additionally, the McFadden's pseudo R² for the logit model is slightly higher than that of the probit model, reinforcing the choice of the logit model as the preferred specification. [If we include the confusion matrix: From the confusion matrix, accuracy of the linear probability model, the probit, and logit models, all yield very similar results, however the logit model is ever so slightly higher.] While the differences between the two models are rather minor, the logit model consistently performs slightly better on both metrics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# average marginal effects \nlibrary(margins)\nmargins(swiss.logit)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAverage marginal effects\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nglm(formula = participation ~ income + age + education + youngkids +     oldkids + foreign, family = binomial(link = \"logit\"), data = SwissLabor)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  income     age education youngkids   oldkids foreignyes\n -0.1699 -0.1064  0.006616   -0.2775 -0.004584     0.2834\n```\n\n\n:::\n:::\n\n\nInterpretations of Average Marginal Effects:\n  Income: There is an decrease in the probability of participating in the Swiss labor force, by about 17 percentage points, as the log of income-labor income increases. \n  Age: There is a decrease in the probability of participation in the Swiss labor force by about 10.6 percentage points, as for each additional increase in decades.\n  Education: there is a slight increase in the probability of participating in the Swiss labor force, by about 0.66 percentage points, for increases in years of education. \n  Youngkids: There is a decrease in probability of participating in the Swiss labor force, by about 27.7 percentage points, for each additional young child.\n  Oldkids: There is an extremely slight decrease, essentially negligiible, in the probability of participation in the Swiss labor force for each additional older child.\n  Foreign: There is an increase in the probability of participating in the Swiss labor force, by about 28.3 percentage points, from people who aren't foreigners to those who are. \n  \nBased on the logit model selected as the final model, we computed the Average Marginal Effects (AMEs). The results indicate that higher non-labor income, older age, and more young children significantly reduce the probability of labor force participation, while being a foreigner substantially increases it by approximately 28.3 percentage points. Education exerts a small positive effect, increasing participation likelihood marginally per additional year of schooling. The number of older children has little meaningful impact on participation. Overall, the logit model effectively indentifies the key socioeconomic and demographic factors that influence labor force participation in Switzerland, confirming our hypothesis that variables such as income, age, education, and family responsibilities may play crucial roles. ",
    "supporting": [
      "04-project_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}